# CSV Insight Copilot

A lightweight analytics copilot for instant exploratory data analysis (EDA) using LLM-powered insights, Python-based charting, and exportable reports.

## Features

- **Automated Dataset Analysis**: Upload a CSV file and get instant structure analysis (column types, missing values, descriptive stats)
- **LLM-Powered Insights**: Get 3 data-driven insights generated by Groq LLM
- **Automatic Visualizations**: Matplotlib charts generated automatically for each insight
- **Executive Summary**: Concise 100-150 word summary of your dataset
- **Exportable Reports**: Download Markdown and HTML reports with embedded charts
- **Modern UI**: Clean React frontend with dark mode support

## Tech Stack

### Backend
- Python 3.11+
- FastAPI + Uvicorn
- LangChain with Groq API
- Pandas, NumPy, Matplotlib
- Pydantic v2

### Frontend
- React 18
- TypeScript
- Vite
- Tailwind CSS
- Material Symbols Icons

## Prerequisites

- Python 3.11+
- Node.js 18+ (for frontend)
- Groq API Key ([Get one here](https://console.groq.com/))

## Installation

### Backend Setup

1. Clone the repository:
```bash
git clone <repository-url>
cd CSV-Insight-Copilot
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create a `.env` file in the root directory:
```env
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile
```

### Frontend Setup

1. Navigate to the frontend directory:
```bash
cd frontend
```

2. Install dependencies:
```bash
npm install
```

3. Create a `.env` file (optional):
```env
VITE_API_URL=http://localhost:8000
```

## Running the Application

### Development Mode

1. Start the backend server:
```bash
# From the root directory
uvicorn app.api:app --reload --host 0.0.0.0 --port 8000
```

2. Start the frontend development server:
```bash
# From the frontend directory
npm run dev
```

3. Open your browser and navigate to `http://localhost:3000`

### Docker Deployment

1. Build and run with Docker Compose:
```bash
docker-compose up --build
```

The backend will be available at `http://localhost:8000` and the frontend at `http://localhost:3000`.

## Usage

1. **Upload CSV**: Click "Analyze Data" and select a CSV file (max 2MB, max 20 columns)
2. **Wait for Analysis**: The system will process your file and generate insights
3. **View Results**: Explore the dataset structure, insights, and visualizations
4. **Download Report**: Download your analysis as Markdown or HTML

## API Endpoints

### POST /analyze
Upload a CSV file for analysis.

**Request**: Multipart form data with `file` field

**Response**: JSON object containing:
- `dataset_overview`: Overview text
- `insights`: Array of insight objects
- `summary`: Executive summary
- `charts`: Array of base64-encoded chart images
- `markdown_report`: Markdown report string
- `html_report`: HTML report string

### GET /health
Health check endpoint.

## Project Structure

```
csv-insight-copilot/
├── app/                 # Backend application
│   ├── api.py          # FastAPI routes
│   ├── profiler.py     # CSV analysis
│   ├── agent.py        # LLM agent
│   ├── charts.py       # Chart generation
│   ├── formatter.py    # Report formatting
│   ├── schemas.py      # Pydantic models
│   ├── prompts.py      # LLM prompts
│   └── config.py       # Configuration
├── frontend/           # React frontend
│   └── src/
│       ├── components/ # React components
│       ├── pages/      # Page components
│       └── api/        # API client
├── charts/             # Generated charts
└── requirements.txt    # Python dependencies
```

## Limitations

- Maximum file size: 2MB
- Maximum columns: 20
- Single CSV file upload only
- No persistent storage (analysis results are not saved)

## License

MIT License

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

